{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00386e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import used libraries\n",
    "import pandas as pd                        # pandas for data analysis\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import matplotlib.pyplot as plt            # matplotlib for data visualisation\n",
    "import json\n",
    "import zstandard as zstd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26e78739",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PATHS ###\n",
    "\n",
    "DIR = \"../data/\"\n",
    "\n",
    "#read\n",
    "TIMESERIES_PATH = DIR + \"df_timeseries_en.tsv.gz\"\n",
    "CHANNELS_PATH   = DIR + \"df_channels_en.tsv.gz\"\n",
    "\n",
    "#write\n",
    "ENT_TIMESERIES_PATH = DIR + \"ent_timeseries_en.tsv.zip\"\n",
    "ENT_CHANNELS_PATH   = DIR + \"ent_channels_en.tsv.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac21de26",
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORTS ###\n",
    "\n",
    "timeseries = pd.read_csv(TIMESERIES_PATH, sep='\\t')\n",
    "channels   = pd.read_csv(CHANNELS_PATH, sep='\\t')\n",
    "\n",
    "timeseries['datetime'] = pd.to_datetime(timeseries['datetime'])\n",
    "channels['join_date'] = pd.to_datetime(channels['join_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e79ba693",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TREATMENT ###\n",
    "\n",
    "#compute the number of subs at the start of the period for each youtuber \n",
    "channels = pd.merge(channels,\n",
    "                    timeseries.sort_values(by='datetime').drop_duplicates('channel')[['channel','subs']].rename(columns={\"subs\":\"initial_subs\"}),\n",
    "                    on = 'channel')\n",
    "\n",
    "#keep only channels that started between 5k and 10k from the entertaining category\n",
    "ent_channels = channels[(channels['initial_subs'] > 5e3) &\n",
    "                        (channels['initial_subs'] < 10e3) &\n",
    "                        (channels['category_cc'] == 'Entertainment')]\n",
    "\n",
    "ent_timeseries = pd.merge(timeseries, ent_channels['channel'], on='channel').drop(['category'], axis=1)\n",
    "\n",
    "#compute the weekly evolution for each channel in timeseries\n",
    "ent_timeseries['evolution'] = ent_timeseries['delta_subs']/ent_timeseries['subs']\n",
    "\n",
    "#compute the evolution score by taking the mean weekly evolution\n",
    "evo_score = ent_timeseries.groupby('channel').mean()['evolution'].rename('evo_score')\n",
    "ent_channels = pd.merge(ent_channels, evo_score, on='channel')\n",
    "\n",
    "# #keeps only 25% top and 25% bottom channels\n",
    "top_channels = ent_channels.nlargest(int(len(ent_channels)*0.25), 'evo_score')[['channel','evo_score']]\n",
    "bottom_channels = ent_channels.nsmallest(int(len(ent_channels)*0.25), 'evo_score')[['channel','evo_score']]\n",
    "evo_channels = pd.concat([top_channels, bottom_channels]).sort_values('evo_score', ascending=False)\n",
    "evo_channels['has_buzzed'] = 0 + 1 * (evo_channels['evo_score'] > bottom_channels['evo_score'].max())\n",
    "\n",
    "ent_channels = pd.merge(ent_channels, evo_channels.drop(['evo_score'], axis=1), on='channel')\n",
    "ent_timeseries = pd.merge(ent_timeseries, ent_channels[['channel', 'has_buzzed']], on='channel')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c037a818",
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXPORTS ###\n",
    "\n",
    "ent_channels.to_csv(ENT_CHANNELS_PATH, index=False, compression={'method':'zip'})\n",
    "ent_timeseries.to_csv(ENT_TIMESERIES_PATH, index=False, compression={'method':'zip'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40da98b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################################\n",
    "############################################ METADATA ############################################\n",
    "##################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bdcbf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "############################################## PATH ##############################################\n",
    "\n",
    "METADATA_PATH   = DIR + \"_raw_yt_metadata.jsonl.zst\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f44ec28a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "1400000\n",
      "1500000\n",
      "1600000\n",
      "1700000\n",
      "1800000\n",
      "1900000\n",
      "2000000\n",
      "2100000\n",
      "2200000\n",
      "2300000\n",
      "2400000\n",
      "2500000\n",
      "2600000\n",
      "2700000\n",
      "2800000\n",
      "2900000\n",
      "3000000\n",
      "3100000\n",
      "3200000\n",
      "3300000\n",
      "3400000\n",
      "3500000\n",
      "3600000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "############################## READ AND SPLIT INTO SMALLER CSV FILES #############################\n",
    "\n",
    "class zreader:\n",
    "\n",
    "    def __init__(self, file, chunk_size=16384):\n",
    "        self.fh = open(file, 'rb')\n",
    "        self.chunk_size = chunk_size\n",
    "        self.dctx = zstd.ZstdDecompressor()\n",
    "        self.reader = self.dctx.stream_reader(self.fh)\n",
    "        self.buffer = ''\n",
    "\n",
    "    def readlines(self):\n",
    "        while True:\n",
    "            chunk = self.reader.read(self.chunk_size).decode(\"utf-8\", errors=\"ignore\")\n",
    "            if not chunk:\n",
    "                break\n",
    "            lines = (self.buffer + chunk).split(\"\\n\")\n",
    "\n",
    "            for line in lines[:-1]:\n",
    "                yield line\n",
    "\n",
    "            self.buffer = lines[-1]\n",
    "\n",
    "reader = zreader(METADATA_PATH)\n",
    "metadata = []\n",
    "df_metadata = pd.DataFrame([])\n",
    "\n",
    "idx = 0\n",
    "store_idx = 0\n",
    "save_idx = 0\n",
    "\n",
    "min_upload_date, max_upload_date = pd.to_datetime(\"01-01-2015\"), pd.to_datetime(\"09-30-2019\")\n",
    "for line in reader.readlines():\n",
    "    line_dict = json.loads(line)\n",
    "    \n",
    "    if (pd.to_datetime(line_dict[\"upload_date\"]) < max_upload_date) & \\\n",
    "       (pd.to_datetime(line_dict[\"upload_date\"]) > min_upload_date) & \\\n",
    "       (line_dict['channel_id'] in ent_channels['channel'].values):\n",
    "        \n",
    "        del line_dict['crawl_date']\n",
    "        del line_dict['categories']\n",
    "        \n",
    "        metadata.append(line_dict)\n",
    "    idx += 1\n",
    "    if idx%100000 == 0:\n",
    "        print(idx)\n",
    "    \n",
    "    #store in a dataframe every 1 million\n",
    "    if len(metadata) >= 1000000:\n",
    "        if store_idx < 9 : print(\" - STORE\", store_idx)\n",
    "        df_metadata = pd.concat([df_metadata, pd.DataFrame(metadata)])\n",
    "        metadata = []\n",
    "        store_idx += 1\n",
    "        \n",
    "        \n",
    "    #save dataframe every 10 million\n",
    "    if len(df_metadata) >= 10000000:\n",
    "        print(\" - SAVE \", save_idx)\n",
    "        \n",
    "        S_METADATA_PATH = DIR + \"metadata/_raw_yt_metadata\" + str(save_idx) + \".tsv.zip\"\n",
    "    \n",
    "        df_metadata.to_csv(S_METADATA_PATH, index=False, compression={'method':'zip'})\n",
    "        df_metadata = pd.DataFrame([])\n",
    "        store_idx = 0\n",
    "        save_idx += 1\n",
    "        \n",
    "if store_idx < 9 : print(\" - STORE\", store_idx)\n",
    "df_metadata = pd.concat([df_metadata, pd.DataFrame(metadata)])\n",
    "metadata = []\n",
    "store_idx += 1\n",
    "\n",
    "print(\" - SAVE \", save_idx)\n",
    "        \n",
    "S_METADATA_PATH = DIR + \"metadata/_raw_yt_metadata\" + str(save_idx) + \".tsv.zip\"\n",
    "\n",
    "df_metadata.to_csv(S_METADATA_PATH, index=False, compression={'method':'zip'})\n",
    "df_metadata = pd.DataFrame([])\n",
    "store_idx = 0\n",
    "save_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6c05b8f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start metadata  6\n",
      "Path done - \n",
      "Read done - \n",
      "Treatment done - \n",
      "Write done -\n",
      "Done metadata  6\n"
     ]
    }
   ],
   "source": [
    "# TREAT THE 6 METADATA\n",
    "for i in range(7):\n",
    "    print(\"Start metadata \", i)\n",
    "    \n",
    "    # PATH\n",
    "    METADATA_PATH = DIR + \"metadata/_raw_yt_metadata\" + str(i) + \".tsv.zip\"\n",
    "    ENT_METADATA_PATH = DIR + \"metadata/ent_metadata\" + str(i) + \".tsv.zip\"\n",
    "    print(\"Path done - \")\n",
    "    \n",
    "    # READ\n",
    "    metadata = pd.read_csv(METADATA_PATH)\n",
    "    print(\"Read done - \")\n",
    "    \n",
    "    # TREATMENT\n",
    "    metadata = metadata.rename(columns={'channel_id':'channel'})\n",
    "    ent_metadata = pd.merge(metadata, ent_channels['channel'])\n",
    "    print(\"Treatment done - \")\n",
    "    \n",
    "    # WRITE\n",
    "    ent_metadata.to_csv(ENT_METADATA_PATH, index=False, compression={'method':'zip'})\n",
    "    print(\"Write done -\")\n",
    "    \n",
    "    print(\"Done metadata \", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bbd77bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start metadata  0\n",
      "Path done - \n",
      "Read done - \n",
      "Concat done - \n",
      "Start metadata  1\n",
      "Path done - \n",
      "Read done - \n",
      "Concat done - \n",
      "Start metadata  2\n",
      "Path done - \n",
      "Read done - \n",
      "Concat done - \n",
      "Start metadata  3\n",
      "Path done - \n",
      "Read done - \n",
      "Concat done - \n",
      "Start metadata  4\n",
      "Path done - \n",
      "Read done - \n",
      "Concat done - \n",
      "Start metadata  5\n",
      "Path done - \n",
      "Read done - \n",
      "Concat done - \n",
      "Start metadata  6\n",
      "Path done - \n",
      "Read done - \n",
      "Concat done - \n",
      "Write done -\n"
     ]
    }
   ],
   "source": [
    "# STORE ALL DATAFRAMES IN ONLY ONE\n",
    "ent_metadata = pd.DataFrame()\n",
    "for i in range(7):\n",
    "    print(\"Start metadata \", i)\n",
    "    \n",
    "    # PATH\n",
    "    METADATA_PATH = DIR + \"metadata/ent_metadata\" + str(i) + \".tsv.zip\"\n",
    "    print(\"Path done - \")\n",
    "    \n",
    "    # READ\n",
    "    metadata = pd.read_csv(METADATA_PATH)\n",
    "    print(\"Read done - \")\n",
    "    \n",
    "    # CONCAT\n",
    "    ent_metadata = pd.concat([ent_metadata, metadata], ignore_index=True)\n",
    "    print(\"Concat done - \")\n",
    "\n",
    "\n",
    "# WRITE\n",
    "ENT_METADATA_PATH = DIR + \"ent_metadata_en.tsv.zip\"\n",
    "ent_metadata.to_csv(ENT_METADATA_PATH, index=False, compression={'method':'zip'})\n",
    "print(\"Write done -\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "61f65eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KEEP COMMON CHANNELS BETWEEN df_channels, df_metadata AND df_timeseries\n",
    "# df_metadata HAS LESS CHANNELS THAN df_channels AND df_timeseries (SOME CHANNELS WITHOUT ANY VIDEO ?)\n",
    "\n",
    "#dir\n",
    "DIR = \"../data/\"\n",
    "\n",
    "#read path\n",
    "TIMESERIES_PATH = DIR + \"ent_timeseries_en.tsv.zip\"\n",
    "CHANNELS_PATH   = DIR + \"ent_channels_en.tsv.zip\"\n",
    "METADATA_PATH   = DIR + \"ent_metadata_en.tsv.zip\"\n",
    "\n",
    "#imports\n",
    "timeseries = pd.read_csv(TIMESERIES_PATH)\n",
    "channels   = pd.read_csv(CHANNELS_PATH)\n",
    "metadata   = pd.read_csv(METADATA_PATH)\n",
    "\n",
    "#treatment\n",
    "channel_ids = metadata[['channel']].drop_duplicates()\n",
    "ent_channels = pd.merge(channels, channel_ids)\n",
    "ent_timeseries = pd.merge(timeseries, channel_ids)\n",
    "\n",
    "#write path\n",
    "ENT_TIMESERIES_PATH = DIR + \"ent_timeseries_en.tsv.zip\"\n",
    "ENT_CHANNELS_PATH   = DIR + \"ent_channels_en.tsv.zip\"\n",
    "\n",
    "#exports\n",
    "ent_channels.to_csv(ENT_CHANNELS_PATH, index=False, compression={'method':'zip'})\n",
    "ent_timeseries.to_csv(ENT_TIMESERIES_PATH, index=False, compression={'method':'zip'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "65477aa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_cc</th>\n",
       "      <th>join_date</th>\n",
       "      <th>channel</th>\n",
       "      <th>name_cc</th>\n",
       "      <th>subscribers_cc</th>\n",
       "      <th>videos_cc</th>\n",
       "      <th>subscriber_rank_sb</th>\n",
       "      <th>weights</th>\n",
       "      <th>initial_subs</th>\n",
       "      <th>evo_score</th>\n",
       "      <th>has_buzzed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Entertainment</td>\n",
       "      <td>2013-05-03</td>\n",
       "      <td>UCMxtWuqP6Ktk1tsSZSstaug</td>\n",
       "      <td>Haryanvi Maina</td>\n",
       "      <td>8830000</td>\n",
       "      <td>1619</td>\n",
       "      <td>666.0</td>\n",
       "      <td>2.0870</td>\n",
       "      <td>9043.500000</td>\n",
       "      <td>0.043476</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Entertainment</td>\n",
       "      <td>2006-02-27</td>\n",
       "      <td>UCDfk8ogO6QGeJAYCY0QDzKw</td>\n",
       "      <td>Stephen Sharer</td>\n",
       "      <td>7230000</td>\n",
       "      <td>549</td>\n",
       "      <td>867.0</td>\n",
       "      <td>2.0870</td>\n",
       "      <td>8843.000000</td>\n",
       "      <td>0.039752</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Entertainment</td>\n",
       "      <td>2015-11-24</td>\n",
       "      <td>UCAgx4HcQIYn9lM0rhtIuH9w</td>\n",
       "      <td>HZHtube Kids Fun</td>\n",
       "      <td>6570000</td>\n",
       "      <td>358</td>\n",
       "      <td>914.0</td>\n",
       "      <td>2.0870</td>\n",
       "      <td>6100.000000</td>\n",
       "      <td>0.040441</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Entertainment</td>\n",
       "      <td>2015-06-13</td>\n",
       "      <td>UCQcf-d098cNGGl3bPGGjHBg</td>\n",
       "      <td>OLIE THE CUB</td>\n",
       "      <td>6820000</td>\n",
       "      <td>778</td>\n",
       "      <td>941.0</td>\n",
       "      <td>2.0870</td>\n",
       "      <td>5181.000000</td>\n",
       "      <td>0.042452</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Entertainment</td>\n",
       "      <td>2017-04-26</td>\n",
       "      <td>UC977n5nXRn8MDuGQjwxkOLw</td>\n",
       "      <td>PC Bob and Mr Bean: ...</td>\n",
       "      <td>6730000</td>\n",
       "      <td>3377</td>\n",
       "      <td>943.0</td>\n",
       "      <td>2.0870</td>\n",
       "      <td>6468.000000</td>\n",
       "      <td>0.051014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>Entertainment</td>\n",
       "      <td>2010-06-04</td>\n",
       "      <td>UCswGzcZ3DcBXN5Pc3J7d9Mg</td>\n",
       "      <td>BlaakowDancer</td>\n",
       "      <td>10200</td>\n",
       "      <td>65</td>\n",
       "      <td>977320.0</td>\n",
       "      <td>53.1435</td>\n",
       "      <td>7284.625000</td>\n",
       "      <td>0.001790</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>Entertainment</td>\n",
       "      <td>2011-03-01</td>\n",
       "      <td>UChN6SlSBv21jbp6n1XRSbJA</td>\n",
       "      <td>thesongadayproject</td>\n",
       "      <td>10100</td>\n",
       "      <td>2624</td>\n",
       "      <td>977759.0</td>\n",
       "      <td>53.1435</td>\n",
       "      <td>9963.000000</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>Entertainment</td>\n",
       "      <td>2012-12-17</td>\n",
       "      <td>UCOioqCYGI_pOUWGGD1cMPCQ</td>\n",
       "      <td>Taylor Swift Brasil</td>\n",
       "      <td>10100</td>\n",
       "      <td>257</td>\n",
       "      <td>978347.0</td>\n",
       "      <td>53.1435</td>\n",
       "      <td>5840.744186</td>\n",
       "      <td>0.002987</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>Entertainment</td>\n",
       "      <td>2013-12-27</td>\n",
       "      <td>UCQV1dyQqE8dtgWU6U_Rg0WQ</td>\n",
       "      <td>CrazySuperGamer</td>\n",
       "      <td>10300</td>\n",
       "      <td>38</td>\n",
       "      <td>978503.0</td>\n",
       "      <td>53.1435</td>\n",
       "      <td>9130.250000</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>Entertainment</td>\n",
       "      <td>2013-08-13</td>\n",
       "      <td>UCJfL91l-gpj2j8rO6u6tj9A</td>\n",
       "      <td>Pen N Camera</td>\n",
       "      <td>10000</td>\n",
       "      <td>53</td>\n",
       "      <td>987365.0</td>\n",
       "      <td>53.1435</td>\n",
       "      <td>8527.666667</td>\n",
       "      <td>0.001098</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1258 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        category_cc   join_date                   channel  \\\n",
       "0     Entertainment  2013-05-03  UCMxtWuqP6Ktk1tsSZSstaug   \n",
       "1     Entertainment  2006-02-27  UCDfk8ogO6QGeJAYCY0QDzKw   \n",
       "2     Entertainment  2015-11-24  UCAgx4HcQIYn9lM0rhtIuH9w   \n",
       "3     Entertainment  2015-06-13  UCQcf-d098cNGGl3bPGGjHBg   \n",
       "4     Entertainment  2017-04-26  UC977n5nXRn8MDuGQjwxkOLw   \n",
       "...             ...         ...                       ...   \n",
       "1253  Entertainment  2010-06-04  UCswGzcZ3DcBXN5Pc3J7d9Mg   \n",
       "1254  Entertainment  2011-03-01  UChN6SlSBv21jbp6n1XRSbJA   \n",
       "1255  Entertainment  2012-12-17  UCOioqCYGI_pOUWGGD1cMPCQ   \n",
       "1256  Entertainment  2013-12-27  UCQV1dyQqE8dtgWU6U_Rg0WQ   \n",
       "1257  Entertainment  2013-08-13  UCJfL91l-gpj2j8rO6u6tj9A   \n",
       "\n",
       "                      name_cc  subscribers_cc  videos_cc  subscriber_rank_sb  \\\n",
       "0              Haryanvi Maina         8830000       1619               666.0   \n",
       "1              Stephen Sharer         7230000        549               867.0   \n",
       "2            HZHtube Kids Fun         6570000        358               914.0   \n",
       "3                OLIE THE CUB         6820000        778               941.0   \n",
       "4     PC Bob and Mr Bean: ...         6730000       3377               943.0   \n",
       "...                       ...             ...        ...                 ...   \n",
       "1253            BlaakowDancer           10200         65            977320.0   \n",
       "1254       thesongadayproject           10100       2624            977759.0   \n",
       "1255      Taylor Swift Brasil           10100        257            978347.0   \n",
       "1256          CrazySuperGamer           10300         38            978503.0   \n",
       "1257             Pen N Camera           10000         53            987365.0   \n",
       "\n",
       "      weights  initial_subs  evo_score  has_buzzed  \n",
       "0      2.0870   9043.500000   0.043476           1  \n",
       "1      2.0870   8843.000000   0.039752           1  \n",
       "2      2.0870   6100.000000   0.040441           1  \n",
       "3      2.0870   5181.000000   0.042452           1  \n",
       "4      2.0870   6468.000000   0.051014           1  \n",
       "...       ...           ...        ...         ...  \n",
       "1253  53.1435   7284.625000   0.001790           0  \n",
       "1254  53.1435   9963.000000   0.000297           0  \n",
       "1255  53.1435   5840.744186   0.002987           0  \n",
       "1256  53.1435   9130.250000   0.000869           0  \n",
       "1257  53.1435   8527.666667   0.001098           0  \n",
       "\n",
       "[1258 rows x 11 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent_channels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ada')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "18c32a2b66552a3f09b8a3b497862286fc4b79643dbf6273d2fe975b8b827621"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
